"""
This type stub file was generated by pyright.
"""

import numpy as np
from enum import Enum
from typing import List, Any

from numpy._typing import NDArray

from picamera2 import Picamera2 as Picamera2

"""
This code is based on multiple sources:

https://github.com/rbgirshick/fast-rcnn
https://github.com/ultralytics/ultralytics
https://github.com/see--/keras-centernet
https://github.com/stefanopini/simple-HigherHRNet
"""
def nms(dets: np.ndarray, scores: np.ndarray, iou_thres: float = ..., max_out_dets: int = ...) -> List[int]:
    """
    Perform Non-Maximum Suppression (NMS) on detected bounding boxes.

    Args:
        dets (np.ndarray): Array of bounding box coordinates of shape (N, 4) representing [y1, x1, y2, x2].
        scores (np.ndarray): Array of confidence scores associated with each bounding box.
        iou_thres (float, optional): IoU threshold for NMS. Default is 0.5.
        max_out_dets (int, optional): Maximum number of output detections to keep. Default is 300.

    Returns:
        List[int]: List of indices representing the indices of the bounding boxes to keep after NMS.

    """
    ...

def combined_nms(batch_boxes, batch_scores, iou_thres: float = ..., conf: float = ..., max_out_dets: int = ...) -> list[Any]:
    ...

def combined_nms_seg(batch_boxes, batch_scores, batch_masks, iou_thres: float = ..., conf: float = ..., max_out_dets: int = ...) -> list[Any]:
    ...

class BoxFormat(Enum):
    YMIM_XMIN_YMAX_XMAX = ...
    XMIM_YMIN_XMAX_YMAX = ...
    XMIN_YMIN_W_H = ...
    XC_YC_W_H = ...


def convert_to_ymin_xmin_ymax_xmax_format(boxes, orig_format: BoxFormat) -> NDArray[Any]:
    """
    Changes the box from one format to another (XMIN_YMIN_W_H --> YMIM_XMIN_YMAX_XMAX )

    Also support in same format mode (returns the same format)

    :param boxes:
    :param orig_format:
    :return: box in format YMIM_XMIN_YMAX_XMAX
    """
    ...

def clip_boxes(boxes: np.ndarray, h: int, w: int) -> np.ndarray:
    """
    Clip bounding boxes to stay within the image boundaries.

    Args:
        boxes (numpy.ndarray): Array of bounding boxes in format [y_min, x_min, y_max, x_max].
        h (int): Height of the image.
        w (int): Width of the image.

    Returns:
        numpy.ndarray: Clipped bounding boxes.
    """
    ...

def scale_boxes(boxes: np.ndarray, h_image: int, w_image: int, h_model: int, w_model: int, preserve_aspect_ratio: bool, normalized: bool = ...) -> np.ndarray:
    """
    Scale and offset bounding boxes based on model output size and original image size.

    Args:
        boxes (numpy.ndarray): Array of bounding boxes in format [y_min, x_min, y_max, x_max].
        h_image (int): Original image height.
        w_image (int): Original image width.
        h_model (int): Model output height.
        w_model (int): Model output width.
        preserve_aspect_ratio (bool): Whether to preserve image aspect ratio during scaling

    Returns:
        numpy.ndarray: Scaled and offset bounding boxes.
    """
    ...

def scale_coords(kpts: np.ndarray, h_image: int, w_image: int, h_model: int, w_model: int, preserve_aspect_ratio: bool) -> np.ndarray:
    """
    Scale and offset keypoints based on model output size and original image size.

    Args:
        kpts (numpy.ndarray): Array of bounding keypoints in format [..., 17, 3]  where the last dim is (x, y, visible).
        h_image (int): Original image height.
        w_image (int): Original image width.
        h_model (int): Model output height.
        w_model (int): Model output width.
        preserve_aspect_ratio (bool): Whether to preserve image aspect ratio during scaling

    Returns:
        numpy.ndarray: Scaled and offset bounding boxes.
    """
    ...

def clip_coords(kpts: np.ndarray, h: int, w: int) -> np.ndarray:
    """
    Clip keypoints to stay within the image boundaries.

    Args:
        kpts (numpy.ndarray): Array of bounding keypoints in format [..., 17, 3]  where the last dim is (x, y, visible).
        h (int): Height of the image.
        w (int): Width of the image.

    Returns:
        numpy.ndarray: Clipped bounding boxes.
    """
    ...

PARTS = ...
class COCODrawer:
    def __init__(self, categories, imx500, needs_rescale_coords=...) -> None:
        ...
    
    def get_coords(self, annotation, metadata: dict, picam2: Picamera2, stream) -> tuple[int, int, int, int]:
        ...
    
    def draw_bounding_box(self, img, annotation, class_id, score, metadata: dict, picam2: Picamera2, stream) -> None:
        ...
    
    def draw_keypoints(self, img, keypoints, min_confidence, metadata: dict, picam2: Picamera2, stream) -> None:
        ...
    
    def annotate_image(self, img, b, s, c, k, box_min_conf, kps_min_conf, metadata: dict, picam2: Picamera2, stream) -> None:
        ...
    
    def overlay_masks(self, picam2, masks, scores, colors, score_threshold=..., mask_threshold=...) -> None:
        ...
    


def softmax(x) -> Any:
    ...

def crop_mask(masks, boxes):
    """
    It takes a mask and a bounding box, and returns a mask that is cropped to the bounding box

    Args:
      masks (numpy.ndarray): [h, w, n] tensor of masks
      boxes (numpy.ndarray): [n, 4] tensor of bbox coordinates in relative point form

    Returns:
      (numpy.ndarray): The masks are being cropped to the bounding box.
    """
    ...

